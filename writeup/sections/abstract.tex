\begin{abstract}
	With a set of musical samples in ABC notation, we can generate music with a character-level LSTM. We can accomplish this task by feeding LSTM musical characters in a sequence, and the network would slowly learn to predict the upcoming sequence of notes. Once trained, a model could generate music samples based on a short sequence of prompted notes. The style of the music generated by our final model has a rich, mature, and elaborate feel. A point of comparison could be made against a standard RNN. By modifying the network layer size and dropout rate, we could tune our model to generate a range of musical samples. After tuning, we found that our LSTM created more elegant musical samples than a traditional recurrent neural network. The ability of the LSTM to drop information in three different areas allows it to resemble the original samples better than a standard RNN. Our LSTM trained faster and created better music than our RNN.
\end{abstract}
